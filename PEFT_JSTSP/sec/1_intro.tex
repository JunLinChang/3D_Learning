\section{Introduction}
\label{sec:intro}
\input{fig/sota}

The widespread adoption of 3D scanning technology has propelled point cloud learning into a critical research area, with applications spanning autonomous driving~\cite{yang2024visual,song2024graphbev,chen20203d}, VR/AR~\cite{casado2023rendering,garrido2021point}, and robotics~\cite{wang2021trajectory,chen2022direct,christen2023learning}. 
However, unlike structured image data defined on dense grids, point clouds exhibit three fundamental properties that shape their feature learning: (1) Sparsity (non-uniform sampling with large empty spaces), (2) Unstructuredness (lack of explicit neighborhood relationships), and (3) Permutation invariance (order-agnostic point sets). 
These properties demand architectures that can dynamically model local geometric structures while preserving global consistency, i.e., a challenge unmet by conventional grid-based deep learning paradigms. 
While prior work has developed specialized architectures~\cite{qi2017pointnet, li2018pointcnn, qian2022pointnext, qi2017pointnet++, wang2019dynamic, wu2024point} to address these challenges, the prevailing paradigm for adapting pre-trained models, i.e., full fine-tuning, remains computationally expensive and often unnecessary.

In this work, we surprisingly find that state-of-the-art performance can be achieved by selectively updating only a minimal parameter subset while keeping the majority of the pre-trained backbone fixed. 
Our findings reveal two key insights:
(1) The initial layer point cloud networks learn general geometric priors (e.g., local surface geometries, neighborhood relationships) that demonstrate strong cross-task invariance. These foundational features maintain their discriminative power across diverse applications, eliminating the need for exhaustive re-training.
(2) Effective task adaptation primarily requires adjustments to local structural processing rather than global feature transformations. This locality constraint enables efficient optimization through focused updates to region-specific parameters while preserving globally learned representations.

To implement these insights, we introduce Hierarchical Ladder Network (HLN), Local-Global Fusion (LGF) and Dynamic Prompt Generation modules that processes raw point clouds in parallel with the frozen backbone,  combines frozen backbone features with lightweight task-specific adaptations, bridges frozen backbone features with lightweight, task-specific adaptations respectively. 

\lr{revise these three paragraph, HLN, LGF, dynamic prompts...}
\lr{1. HLN} To address the granularity limitation of global attention mechanisms in capturing fine local structures, we propose a Hierarchical Ladder Network (HLN). This architecture operates in parallel to the frozen backbone, directly processing raw point clouds through tiered feature extractors to preserve multi-scale local geometric details (e.g., surface curvatures, neighborhood connectivity). Unlike conventional side networks, HLN employs skip connections and progressive downsampling to maintain spatial fidelity while reducing computational overhead, ensuring complementary local information is retained for downstream tasks. 

\lr{2. LGF} We then introduce hierarchical local-global fusion (LGF) mechanism that bridges frozen backbone features with lightweight, task-specific adaptations. This approach allows diverse downstream tasks (e.g., classification, segmentation) to share a single frozen backbone, achieving competitive performance with only 2.71\% to 7.69\% of the parameters for downstream tasks, e.g., object classification and dense prediction.

\lr{3. dynamic prompts}Additionally, our method generates dynamic prompts from these fused features to enhance the backboneâ€™s capacity for producing optimized global features across diverse downstream tasks.

\lr{hard to understand these two paragraphs}
The success of pre-trained models in NLP~\cite{devlin2018bert, brown2020language} and computer vision~\cite{he2020momentum, chen2020improved} has inspired similar approaches for point clouds~\cite{pang2022masked, yu2022point, zhang2022point, afham2022crosspoint}. Current methods typically employ full fine-tuning, which faces three key challenges: (1) overfitting and catastrophic forgetting from updating all parameters, (2) storage inefficiency from task-specific models, and (3) high computational costs that limit accessibility.

Parameter-Efficient Fine-Tuning (PEFT)~\cite{houlsby2019parameter, jie2023fact, karimi2021compacter} addresses these issues by freezing most parameters while selectively updating key components. Current PEFT approaches primarily employ three strategies: (1) Adapters~\cite{houlsby2019parameter, chen2022adaptformer}, which integrate lightweight intermediate networks between model layers; (2) Prompt tuning~\cite{li2021prefix, lester-etal-2021-power}, where learnable continuous embeddings are prepended to the input sequence; and (3) Ladder networks~\cite{sung2022lst}, utilizing parallel architectures for hierarchical feature refinement.

However, our experiments (Sec.~\ref{sec:classification}) show these vision/NLP methods underperform on point clouds. This raises a crucial question: how to develop point cloud-specific PEFT that matches or exceeds full fine-tuning's accuracy while maintaining efficiency? To handle this challenge, we propose Point Ladder Tuning (PLT), which enhances Ladder Side Tuning with two key innovations: A Hierarchical Ladder Network (HLN) that extracts detailed local features from raw points; A Local-Global Fusion (LGF) module that combines these with the backbone's global features. Additionally, our adaptive prompt generation module creates instance-specific, multi-scale prompts to efficiently guide the backbone's feature refinement.

Our primary contributions are as follows:

\begin{itemize} 
	\item We present Point Ladder Tuning (PLT), a parameter-efficient fine-tuning method for point cloud data that combines a hierarchical Ladder Network for local information extraction and a Local-Global Fusion (LGF) module for multi-scale feature integration. 
	\item We introduce a prompt generation module that linearly maps the output of the LGF module, injecting multi-scale information directly into the backbone network to further enhance performance. 
	\item \lr{experiment results are not contribution, think about it}Extensive experiments demonstrate that PLT achieves performance comparable to, and often surpassing, full fine-tuning across various tasks and datasets, while requiring significantly fewer parameters. 
\end{itemize}

%The growing accessibility of 3D scanning technology has elevated 3D point cloud learning to an emerging research area with diverse applications across computer vision and graphics fields, including autonomous driving (add citation), virtual and augmented reality (VR/AR) (add citation), and robotics (add citation).  
%Unlike images, point clouds are inherently unstructured, sparse, and permutation-invariant, which poses unique challenges for effective analysis and processing. 
%Consequently, deep learning-based methods~\cite{qi2017pointnet, li2018pointcnn,qian2022pointnext,qi2017pointnet++,wang2019dynamic,wu2024point,wu2022point,zhang2022patchformer,park2022fast,zhao2021point,guo2021pct,ma2022rethinking} specifically tailored for point cloud learning have been developed, incorporating specialized modules to directly handle point cloud data and achieving substantial improvements in performance.

%The widespread availability of 3D scanning technology has elevated 3D point cloud learning into a rapidly growing research field with applications across computer vision and graphics, notably in autonomous driving~\cite{yang2024visual,song2024graphbev,chen20203d}, virtual and augmented reality (VR/AR)~\cite{casado2023rendering,garrido2021point}, and robotics~\cite{wang2021trajectory,chen2022direct,christen2023learning}. Unlike images, point clouds are inherently unstructured, sparse, and permutation-invariant, which introduces unique challenges for analysis and processing. Consequently, deep learning approaches specifically tailored for point cloud data~\cite{qi2017pointnet, li2018pointcnn, qian2022pointnext, qi2017pointnet++, wang2019dynamic, wu2024point} have been developed, achieving notable performance gains by incorporating modules designed to handle these challenges directly.

%\blk{Recently, inspired by the success of pre-trained models in natural language processing~\cite{devlin2018bert,brown2020language,2020ALBERT,raffel2020exploring,touvron2023llama,team2024gemma} and computer vision~\cite{he2020momentum,chen2020improved,chen2021empirical,he2022masked,xie2022simmim,yeh2022decoupled}, a series of works~\cite{pang2022masked,yu2022point,zhang2022point,afham2022crosspoint,dong2022autoencoders,liu2022masked,xie2020pointcontrast,qi2023contrast,wang2021unsupervised} have also emerged in the field of point cloud analysis.After pre-training, these methods employ a classic full fine-tuning strategy to adapt to downstream tasks, resulting in significant performance improvements and faster convergence compared to training from scratch.However, fully fine-tuning techniques may be suboptimal for point cloud processing for three reasons: 1) Updating all parameters of the pre-trained model can lead to overfitting and catastrophic forgetting, undermining the rich embedding knowledge acquired during the pre-training phase and resulting in poor performance. 2) Each point cloud analysis task and dataset requires separate copies of model parameters, which can pose storage challenges as demand increases. 3) To fully leverage the prior knowledge from the pre-training dataset, large models are often necessary. Full fine-tuning can incur significant computational costs, including increased GPU memory usage and extended training times, limiting accessibility for researchers with poor hardware resources.}

%Inspired by the success of pre-trained models in natural language processing~\cite{devlin2018bert, brown2020language} and computer vision~\cite{he2020momentum, chen2020improved}, recent research has extended this paradigm to point cloud analysis~\cite{pang2022masked, yu2022point, zhang2022point, afham2022crosspoint} (\lr{inspire by what kind of specific technology}), where pre-trained models typically undergo full fine-tuning for downstream tasks. While effective, full fine-tuning for point clouds has limitations: (1) Updating all model parameters can lead to overfitting and catastrophic forgetting, diminishing the benefits of pre-trained embeddings. (2) Each task and dataset requires its own model, leading to storage inefficiencies as demand grows. (3) Full fine-tuning incurs high computational costs, including increased GPU memory usage and extended training times, which may limit accessibility for researchers with constrained hardware resources.
%
%To address these limitations, our research explores Parameter-Efficient Fine-Tuning (PEFT)~\cite{houlsby2019parameter, jie2023fact, karimi2021compacter}, a strategy that has gained traction in NLP and vision by freezing most model parameters and allowing selective, efficient updates. PEFT approaches allow comparable or even improved performance over full fine-tuning while significantly reducing the number of parameter updates. Examples include (1) Adapters~\cite{houlsby2019parameter, chen2022adaptformer}, which insert lightweight networks into Transformer layers; (2) Prompt Tuning~\cite{li2021prefix, lester-etal-2021-power}, which adds learnable parameters to the input sequence; and (3) Ladder Side Tuning~\cite{sung2022lst}, which uses an independent Ladder network to refine intermediate representations. These techniques have shown promising performance in transferring pre-trained knowledge while maintaining computational efficiency.
%
%However, our empirical analysis (see Sec.~\ref{sec:classification}) reveals that directly adapting fine-tuning strategies from language and vision models to point cloud data often results in sub-optimal performance. This observation highlight a critical question: How can we design a fine-tuning approach specifically optimized for point clouds that not only achieves but potentially surpasses the performance of full fine-tuning, while remaining efficient and effective? Addressing this challenge is essential for advancing parameter-efficient techniques tailored to the unique demands of 3D data.
%
%In response, we introduce a novel fine-tuning approach for point cloud data, termed Point Ladder Tuning (PLT), which builds upon Ladder Side Tuning. While the backbone networkâ€™s attention mechanisms effectively capture global semantic information, which lacks the granularity needed for fine local detail. To overcome this, PLT incorporates a hierarchical Ladder Network (HLN) to directly extract local information from raw input, enhancing the detail available for downstream tasks. Furthermore, we propose a Local-Global Fusion (LGF) module, which adaptively combines local information from the Ladder Network with global features from the backbone network, generating rich multi-scale representations essential for improving performance.
%
%
%To further optimize the pre-trained backbone for specific tasks, we introduce an adaptive prompt generation module. This module learns to scale and translate the fused features, producing instance-specific, multi-scale prompts that enable the backbone to refine its features with high efficiency and effectiveness.





