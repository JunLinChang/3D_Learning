\section{Introduction}
\label{sec:intro}
% \input{fig/sota}

The rapid advancement of 3D sensing technologies, such as Light Detection and Ranging (LiDAR), depth cameras (structured light/time-of-flight), photogrammetry, and stereo vision, has led to the widespread availability of point cloud data, driving the development of learning-based 3D imaging and understanding methods. Applications span a variety of domains, including autonomous driving~\cite{yang2024visual,song2024graphbev,chen20203d}, virtual/augmented reality~\cite{casado2023rendering,garrido2021point}, and robotics~\cite{wang2021trajectory,chen2022direct,christen2023learning}. 
%Unlike regular 2D images, point clouds are inherently sparse, unstructured, high-dimensional, uncompressed and permutation-invariant, posing unique challenges for representation learning. 
Unlike regular 2D images, point clouds are inherently sparse, unstructured, high-dimensional, and permutation-invariant, while also exhibiting irregular sampling, varying densities, and missing geometric connectivity. These raw 3D measurements are typically uncompressed, noisy, and non-uniformly distributed in space. These characteristics pose unique challenges for representation learning, require models capable of capturing fine-grained local geometric structures while preserving global spatial coherence, i.e., tasks that conventional grid-based architectures are ill-suited to handle.
%These characteristics require models capable of capturing fine-grained local geometric structures while preserving global spatial coherenceâ€”tasks that conventional grid-based architectures are ill-suited to handle.

The recent advances in deep learning models that tailored for point clouds~\cite{qi2017pointnet, qi2017pointnet++, li2018pointcnn, qian2022pointnext, wang2019dynamic, wu2024point} as well as pre-trained models in NLP~\cite{devlin2018bert, brown2020language} and vision~\cite{he2020momentum, chen2020improved}, have demonstrated remarkable effectiveness. These developments have significantly advanced self-supervised pre-training methods for point clouds~\cite{pang2022masked, yu2022point, zhang2022point, afham2022crosspoint}.
%These approaches typically rely on full fine-tuning, updating all model parameters for downstream tasks. However, this practice suffers from three key limitations: (1) risk of overfitting and catastrophic forgetting, (2) inefficiency in storage due to separate copies of models for each task, and (3) high computational and memory costs, limiting its accessibility in resource-constrained environments.
These methods typically employ full fine-tuning, updating all parameters for downstream tasks. However, this approach faces three major drawbacks: (1) overfitting and catastrophic forgetting risks, (2) storage inefficiency from maintaining separate models per task, and (3) prohibitive computational/memory costs for resource-constrained settings.

To address these issues, Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a promising alternative~\cite{houlsby2019parameter, jie2023fact, karimi2021compacter}. PEFT freezes the majority of pre-trained weights and introduces a small set of trainable parameters for adaptation, including adapters~\cite{houlsby2019parameter}, prompt tuning~\cite{li2021prefix}, and ladder networks~\cite{sung2022lst}. Although these techniques have demonstrated efficacy in language and vision domains, their direct application to 3D point clouds frequently yields suboptimal results, primarily due to the inherent geometric complexity and local structural dependencies characteristic of point cloud data.

\input{fig/sota}

In this work, we propose \textbf{Point Ladder Tuning (PLT)}, a novel PEFT framework specifically designed for point cloud learning. PLT is built upon the observation that (1) the early layers of point cloud encoders learn transferable low-level geometric priors, such as surface curvature and neighborhood topology, that are broadly applicable across tasks, and (2) task-specific adaptation primarily relies on refining localized structural features, rather than re-learning global representations that are already well-established during pre-training.

PLT introduces three key components: Hierarchical Ladder Network (HLN), Local-Global Fusion (LGF), Dynamic Prompt Generation.

\textbf{Hierarchical Ladder Network (HLN)}: A parallel branch that processes raw point clouds to extract multi-resolution local features. Through progressive downsampling, HLN preserves spatial granularity and semantic richness, offering detailed representations crucial for fine-grained tasks like segmentation.

\textbf{Local-Global Fusion (LGF)}: A fusion mechanism that integrates HLN's local features with frozen backbone's global representations at multiple scales. This bridges the gap between task-agnostic global knowledge and task-specific local patterns, enabling more effective and efficient adaptation.

\textbf{Dynamic Prompt Generation}: Building upon the fused representations, PLT generates instance-specific, multi-scale prompts that dynamically modulate the frozen backbone. These adaptive prompts enhance the model's ability to produce task-relevant global features, leading to consistent performance improvements across diverse applications.

These modules work in synergy to achieve highly competitive performance while tuning only a small subset of parameters. Extensive experiments across multiple tasks and datasets demonstrate that PLT achieves state-of-the-art results among PEFT methods, with performance comparable to full fine-tuning while requiring significantly fewer tunable parameters.

%In summary, our contributions are as follows:
%\begin{itemize}
%\item We propose Point Ladder Tuning (PLT), a novel PEFT framework for point cloud learning that combines hierarchical local feature extraction with efficient global adaptation.
%\item We introduce the Hierarchical Ladder Network (HLN) and Local-Global Fusion (LGF) modules, enabling multi-resolution geometric representation and effective integration with frozen pre-trained backbones.
%\item We develop a dynamic prompt generation mechanism to inject task-aware, instance-specific information into the backbone, further boosting performance.
%\end{itemize}

In summary, this work makes these key contributions:
\begin{itemize}
	\item \textbf{Novel parameter-efficient framework for point clouds:} We present PLT that effectively bridges hierarchical local geometric processing with global feature adaptation for point cloud learning. Our framework achieves superior performance while maintaining computational efficiency through minimal parameter updates.
	
	\item \textbf{Multi-scale geometric representation learning:} We propose two innovative components: (i) HLN preserves fine-grained spatial information through progressive downsampling, and (ii) LGF optimally combines multi-resolution local features with frozen backbone representations. Together, these enable comprehensive geometric understanding while maintaining pretrained knowledge.
	
	\item \textbf{Dynamic task-aware adaptation:} We introduce a dynamic prompt generator that creates multi-scale, instance-specific prompts based on combined local and global features. This approach adapts the frozen backbone to different tasks while preserving its original capabilities.
\end{itemize}


% Extensive experiments across multiple tasks and datasets demonstrate that PLT achieves state-of-the-art results among PEFT methods, with performance comparable to full fine-tuning while requiring significantly fewer tunable parameters.

