\section{Related Work}
\label{sec:relatedwork}
The field of point cloud analysis has witnessed significant advancements in recent years, largely driven by the development of self-supervised pre-trained models and fine-tuning techniques. We give a review for pre-trained models and fine-tuning technologies for point cloud analysis.

\subsection{3D Pre-trained Models}
Recent advancements in self-supervised pre-trained models for point cloud data have gained considerable attention due to their strong performance across a range of computer vision tasks. These models are typically trained on extensive unlabeled datasets and later fine-tuned for specific downstream applications. Point cloud pre-training methods can be broadly categorized into three primary approaches: contrastive learning, reconstruction-based learning, and hybrid approaches that integrate both.

In contrastive learning, models like PointContrast~\cite{xie2020pointcontrast} and CrossPoint~\cite{afham2022crosspoint} capture semantic priors by comparing different perspectives of a unified point cloud, effectively learning discriminative features. Reconstruction-based methods, such as PointBERT~\cite{yu2022point} and PointMAE~\cite{pang2022masked}, draw inspiration from NLP and vision models by employing masked prediction and autoencoding frameworks. For instance, PointBERT adapts BERT-style masked patch prediction with a dVAE-based tokenizer for point clouds, while PointMAE reconstructs masked point coordinates through an autoencoder. Hybrid methods like ReCon~\cite{qi2023contrast} combine both contrastive and reconstruction objectives, leveraging multi-modal inputs such as images and text to enrich feature learning during pre-training.

Traditionally, these 3D pre-trained models are fine-tuned for downstream tasks through full parameter updates. However, full fine-tuning can be inefficient, often resulting in the degradation of valuable knowledge gained during pre-training and increasing the risk of catastrophic forgetting. This paper, therefore, investigates more efficient and effective strategies for transferring 3D pre-trained models to downstream tasks while preserving the benefits of pre-training.

\subsection{Parameter Efficient Fine-tuning}
Fine-tuning pre-trained models often demands substantial computational and storage resources. To address these limitations, parameter-efficient fine-tuning (PEFT) techniques have been developed, particularly within natural language processing (NLP) and computer vision. PEFT methods aim to transfer knowledge from pre-trained models to downstream tasks with minimal parameter updates. Adapter-based methods~\cite{houlsby2019parameter, hu2021lora, chen2022adaptformer}, for example, insert lightweight modules into frozen backbone models, allowing adjustments without modifying the entire architecture. AdaptFormer~\cite{chen2022adaptformer}, for instance, adds adapters parallel to feed-forward networks (FFNs) in visual recognition models. Prompt-based approaches~\cite{li2021prefix, jia2022visual} introduce a small number of learnable parameters to the input sequence, as seen in VPT-Deep~\cite{jia2022visual}, which adds trainable tokens at each layer’s input. Ladder Side Tuning (LST)~\cite{sung2022lst} takes a different route, adding side branches that leverage intermediate activations from the pre-trained model for enhanced prediction. However, applying these PEFT techniques directly to 3D point clouds has often yielded suboptimal results.

In recent years, PEFT methods tailored to 3D point cloud models have shown potential for improved performance. For instance, IDPT~\cite{zha2023instance} introduced the first PEFT approach specifically for point clouds, using DGCNN~\cite{wang2019dynamic} to generate instance-level prompts, effectively adapting traditional prompt-based tuning methods. Point-PEFT~\cite{tang2024point} employs adapters to capture local features, while DAPT~\cite{zhou2024dynamic} introduces dynamic adapters that weigh token importance for different downstream tasks. Despite reducing training costs, these methods still struggle with consistent performance across tasks, as freezing pre-trained feature layers can limit the ability to capture fine-grained local features. Additionally, these methods often fall short in integrating local and global information—a critical component for dense prediction tasks~\cite{chen2022vitadapter}.

To overcome these challenges, we propose Point Ladder Tuning (PLT), a method that introduces a hierarchical Ladder Network for direct extraction of local information from point cloud inputs. PLT integrates this local information with global features from the backbone network through an attention-based Local-Global Fusion module, generating rich multi-scale features. This approach minimizes the number of trainable parameters while achieving notable improvements in model performance.
