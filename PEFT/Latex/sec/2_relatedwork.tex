\section{Related Work}
\label{sec:relatedwork}
The field of point cloud analysis has witnessed significant advancements in recent years, largely driven by the development of self-supervised pre-trained models and fine-tuning techniques. We give a review for pre-trained models and fine-tuning technologies for point cloud analysis.

\subsection{3D Pre-trained Models}
% \subsection{3D Shape Analysis}
% The unstructured, sparse, and disordered characteristics of point clouds pose a significant challenge in the field of computer vision. A groundbreaking solution to this problem is PointNet\cite{qi2017pointnet}\cite{wang2019dynamic,wang2018local,li2019deepgcns,zhang2022graph}, which utilizes shared multi-layer perceptrons (MLPs) to efficiently extract global features from point clouds. Subsequent developments, integrating advanced technologies such as graph learning\cite{wang2019dynamic,wang2018local,li2019deepgcns,zhang2022graph}, convolutional methods\cite{li2018pointcnn,wu2019pointconv}, self-attention mechanisms\cite{guo2021pct,zhao2021point,wu2024point}, and Mamba\cite{liang2024pointmamba,liu2024point,wang2024serialized}, have further promoted the progress of this field.

%Recently, self-supervised pre-trained point cloud models have garnered significant attention due to their outstanding performance. These models are trained on vast amounts of unlabeled data and subsequently fine-tuned for various downstream tasks. Point cloud pre-training can be categorized into three main types: contrastive learning-based, reconstruction-based, and a combination of both. In contrastive learning, models like PointContrast\cite{xie2020pointcontrast} and CrossPoint\cite{afham2022crosspoint} leverage rich semantic priors by comparing and learning features from different perspectives of a unified point cloud. PointBERT\cite{yu2022point} adapts concepts from BERT\cite{devlin2018bert}, learning point cloud features by predicting masked patches and comparing them with the output features from dVAE-based point cloud tokenizers. PointMAE\cite{pang2022masked}, inspired by MAE\cite{he2022masked}, directly predicts the coordinates of the masked points using an autoencoder. Meanwhile, ReCon\cite{qi2023contrast} combines contrastive learning and mask reconstruction, integrating additional information such as images and text to enhance the quality of pre-training.

%Currently, 3D pre-trained models are usually transferred to downstream tasks through full fine-tuning. However, this is often inefficient and may undermine the valuable prior knowledge obtained during pre-training, potentially leading to catastrophic forgetting. Therefore, in this paper, we mainly focus on strategies for efficiently and effectively transferring 3D pre-trained models to downstream tasks.

Recent developments in self-supervised pre-trained point cloud models have attracted attention due to their exceptional performance across various computer vision tasks. 
These models are typically trained on large volumes of unlabeled data and later fine-tuned for specific downstream applications. 
Point cloud pre-training can be broadly categorized into three main approaches: contrastive learning-based, reconstruction-based, and hybrid methods that combine both. In contrastive learning, models such as PointContrast~\cite{xie2020pointcontrast} and CrossPoint~\cite{afham2022crosspoint} exploit rich semantic priors by learning features through comparisons of different perspectives of a unified point cloud. PointBERT~\cite{yu2022point} adapts concepts from BERT~\cite{devlin2018bert} by predicting masked patches in the point cloud and comparing them with the output features of dVAE-based point cloud tokenizers. PointMAE~\cite{pang2022masked}, inspired by MAE~\cite{he2022masked}, directly predicts the coordinates of masked points using an autoencoder framework. Meanwhile, ReCon~\cite{qi2023contrast} combines contrastive learning and mask reconstruction, incorporating additional modalities such as images and text to further enhance the quality of pre-training.

Traditionally, 3D pre-trained models are transferred to downstream tasks using full fine-tuning. However, this approach can be inefficient, often leading to the degradation of the valuable prior knowledge learned during pre-training and increasing the risk of catastrophic forgetting. Consequently, this paper focuses on exploring more efficient and effective strategies for transferring 3D pre-trained models to downstream tasks while preserving the performance benefits of pre-training.

\subsection{Parameter Efficient Fine-tuning}

%Fine-tuning pre-trained models can be costly in terms of computation and storage. To address this challenge, many researchers in NLP and computer vision have explored parameter-efficient fine-tuning techniques that enable the transfer of pre-trained knowledge to downstream tasks using only a minimal number of parameters. the Adapter-based methods\cite{houlsby2019parameter,hu2021lora,chen2022adaptformer} typically involve inserting lightweight networks into frozen backbone models to adjust the pre-trained architecture. For instance, AdaptFormer\cite{chen2022adaptformer} adds adapters in parallel to the feed-forward network (FFN) for visual recognition tasks.the Prompt-based methods\cite{li2021prefix, jia2022visual} generally incorporate a small number of learnable parameters into the input sequence. For example, VPT-Deep\cite{jia2022visual} inserts learnable parameters into the input of each layer. Different from the previous two methods, LST\cite{sung2022lst} introduces additional branches that utilize the intermediate activations of the pretrained model as inputs for prediction. However, simply applying these methods to the field of 3D point clouds does not yield satisfactory results.

%Recently, several PEFT methods\cite{zha2023instance,tang2024point,zhou2024dynamic,liang2024parameter,zhang2024positional} designed for pre-training 3D point cloud models have shown significant performance improvements. IDPT\cite{zha2023instance} is the first PEFT method specifically tailored for point clouds, utilizing DGCNN\cite{wang2019dynamic} to generate instance-level prompts, effectively replacing traditional VPT. Point-PEFT\cite{tang2024point} employs adapters to aggregate local features during the fine-tuning process, while DAPT\cite{zhou2024dynamic} introduces dynamic adapters that assess the importance of each token in downstream tasks, generating dynamic weights for each token. Although these methods successfully reduce training costs, achieving consistent performance improvements across various tasks remains challenging. We believe that these approaches depend on freezing the features of pre-trained models as input, which hinders the learning of discriminative local features. Furthermore, they do not fully integrate the global and local information of point clouds, a critical aspect for dense prediction tasks\cite{chen2022vitadapter}. To this end, we propose Point Ladder Tuning(PLT), which utilizes a hierarchical Ladder network to directly extract local information from point cloud inputs and fuses it with the global features of the backbone network through attention to obtain multi-scale features. This method significantly reduces adjustable parameters and achieves remarkable performance.

Fine-tuning pre-trained models can be computationally and storage-intensive. To mitigate these challenges, many researchers in natural language processing (NLP) and computer vision have developed parameter-efficient fine-tuning (PEFT) techniques that enable the transfer of pre-trained knowledge to downstream tasks using a minimal number of parameters. Adapter-based methods~\cite{houlsby2019parameter, hu2021lora, chen2022adaptformer} typically insert lightweight networks into frozen backbone models to adjust the pre-trained architecture. For example, AdaptFormer~\cite{chen2022adaptformer} adds adapters in parallel to the feed-forward network (FFN) for visual recognition tasks. Prompt-based methods~\cite{li2021prefix, jia2022visual} incorporate a small number of learnable parameters into the input sequence, such as VPT-Deep~\cite{jia2022visual}, which inserts learnable parameters at the input of each layer. A different approach is Ladder Side Tuning (LST)~\cite{sung2022lst}, which introduces additional branches that use intermediate activations from the pre-trained model as inputs for prediction. However, simply applying these methods to 3D point clouds does not consistently yield satisfactory results.

Recently, several PEFT methods specifically designed for pre-training 3D point cloud models have shown promising performance improvements. IDPT~\cite{zha2023instance} is the first PEFT approach tailored for point clouds, using DGCNN~\cite{wang2019dynamic} to generate instance-level prompts, replacing traditional VPT methods. Point-PEFT~\cite{tang2024point} employs adapters to aggregate local features during fine-tuning, while DAPT~\cite{zhou2024dynamic} introduces dynamic adapters that assess the importance of each token, generating dynamic weights for downstream tasks. Although these methods reduce training costs, achieving consistent performance improvements across diverse tasks remains challenging. We argue that these approaches, which freeze the features of pre-trained models as input, hinder the learning of discriminative local features. Additionally, they fail to fully integrate global and local information, which is critical for dense prediction tasks~\cite{chen2022vitadapter}. To address these limitations, we propose Point Ladder Tuning (PLT), which utilizes a hierarchical Ladder Network to directly extract local information from point cloud inputs and fuses it with global features from the backbone network via attention mechanisms to generate multi-scale features. This approach significantly reduces the number of adjustable parameters and achieves notable performance improvements.
